{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Find frequent words given topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "def get_freq_words_topic(n = 30,directory = \"Twitter-Get-Old-Tweets-Scraper/gunshoot\"):\n",
    "    '''\n",
    "    print out most frequent words given a topic\n",
    "    Input:\n",
    "        n: number of frequent words desired (i.e: 30)\n",
    "        directory: the directory containing all excel file of certain topic \n",
    "        (i.e: \"Twitter-Get-Old-Tweets-Scraper/gunshoot\")\n",
    "    Return: \n",
    "        maxkey: most frequent words\n",
    "        maxperctg: percentage of these words\n",
    "    \n",
    "    '''\n",
    "\n",
    "    file_names = os.listdir(directory)\n",
    "\n",
    "    #filename = \"Twitter-Get-Old-Tweets-Scraper/tweets_gathered_wedding_#harryandmeghan.csv\"\n",
    "    word_dict = defaultdict(int)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punctuations = string.punctuation\n",
    "    #f = open('filename')\n",
    "    tweet_ids = [] \n",
    "    lines = []\n",
    "    import csv\n",
    "    for filename in file_names:\n",
    "        dirname = directory +'/'+filename\n",
    "        with open(dirname) as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            line_count = 0\n",
    "            sublines=[]\n",
    "            for i,row in enumerate(csv_reader):\n",
    "                if i >0 and (row[9] not in tweet_ids):\n",
    "                    tweet_ids.append(row[9])\n",
    "                    sublines.append(row[5])\n",
    "                    lines.append(row[5])\n",
    "            print(\"finished file {} >> {} lines ({})\".format(filename,len(lines), len(sublines)))\n",
    "    i=0\n",
    "    for line in lines:\n",
    "        subline=line.lower().split()\n",
    "        for s in subline:\n",
    "            if (s not in stop_words) and (s not in punctuations) and (not s.startswith('#')) and (not s.startswith(\".\")) :\n",
    "                word_dict[s] += 1\n",
    "        i+=1\n",
    "\n",
    "    #sorted(word_dict.items(), key=lambda word_dict : word_dict[1])\n",
    "    #print(word_dict)\n",
    "\n",
    "    maxkey = sorted(word_dict, key=word_dict.get, reverse=True)[:n]\n",
    "\n",
    "    maxvalues = [word_dict[s] for s in maxkey]\n",
    "    result_dict={}\n",
    "    for i in range(len(maxkey)):\n",
    "        #print(\"{:20}   {:10}    {:.2f}%\".format(maxkey[i], maxvalues[i], 100*maxvalues[i]/len(lines)))\n",
    "        result_dict[maxkey[i]] =maxvalues[i]/len(lines)\n",
    "    #maxperctg = 100*np.array(maxvalues)/len(lines)\n",
    "    return result_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished file tweets_gathered_gunshoot_#parkland.csv >> 2945 lines (2945)\n",
      "finished file tweets_gathered_gunshoot_#neveragain.csv >> 12835 lines (9890)\n",
      "finished file tweets_gathered_gunshoot_#guncontrolnow.csv >> 16655 lines (3820)\n",
      "finished file tweets_gathered_gunshoot_#marchforourlives.csv >> 17075 lines (420)\n",
      "finished file tweets_gathered_gunshoot_#gunreformnow.csv >> 20173 lines (3098)\n",
      "30\n",
      "<class 'dict'>\n",
      "… 0.3108114806920141\n",
      "gun 0.20467952213354484\n",
      "school 0.11227878847965102\n",
      "students 0.09264858969910277\n",
      "people 0.0773310861051901\n",
      "nra 0.06538442472611906\n",
      "kids 0.06047687503098201\n",
      "need 0.05467704357309275\n",
      "us 0.053388192138006246\n",
      "one 0.0531403360927973\n",
      "like 0.05170277103058544\n",
      "shooting 0.050612204431666086\n",
      "make 0.0475387894710752\n",
      "get 0.0466960789173648\n",
      "time 0.04649779408119764\n",
      "guns 0.046249938035988696\n",
      "children 0.0445149457195261\n",
      "take 0.04377137758389927\n",
      "want 0.043325236702523175\n",
      "high 0.04238338373072919\n",
      "@nra 0.04159024438606058\n",
      "violence 0.04154067317701879\n",
      "support 0.04025182174193229\n",
      "today 0.03866554305259505\n",
      "change 0.03693055073613245\n",
      "mass 0.036682694690923515\n",
      "stop 0.03574084171912953\n",
      "every 0.035492985673920584\n",
      "know 0.03484855995637733\n",
      "it’s 0.03400584940266693\n"
     ]
    }
   ],
   "source": [
    "directory = \"Twitter-Get-Old-Tweets-Scraper/gunshoot\"\n",
    "n =30\n",
    "word_dict = get_freq_words_topic(n, directory)\n",
    "\n",
    "#print(word_dict)\n",
    "print(len(word_dict.keys()))\n",
    "print(type(word_dict))\n",
    "for key in word_dict.keys():\n",
    "    print(key , word_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find frequent words given #Hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "def get_freq_words_hastag(n = 30, filename = \"Twitter-Get-Old-Tweets-Scraper/wedding/tweets_gathered_wedding_#harryandmeghan.csv\"):\n",
    "    '''\n",
    "    print out most frequent words given a hashtag\n",
    "    Input:\n",
    "        n: number of frequent words desired (i.e: 30)\n",
    "        filename: csvfile of certain hashtag\n",
    "        (i.e: \"tweets_gathered_wedding_#harryandmeghan.csv\")\n",
    "        \n",
    "    Return: \n",
    "        maxkey: most frequent words\n",
    "        maxperctg: percentage of these words\n",
    "    '''\n",
    "\n",
    "    #filename = \"Twitter-Get-Old-Tweets-Scraper/tweets_gathered_wedding_#harryandmeghan.csv\"\n",
    "    word_dict = defaultdict(int)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punctuations = string.punctuation\n",
    "    #f = open('filename')\n",
    "    tweet_ids = [] \n",
    "    lines = []\n",
    "    import csv\n",
    "\n",
    "    with open(filename) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        sublines=[]\n",
    "        for i,row in enumerate(csv_reader):\n",
    "            if i >0 and (row[9] not in tweet_ids):\n",
    "                tweet_ids.append(row[9])\n",
    "                sublines.append(row[5])\n",
    "                lines.append(row[5])\n",
    "        print(\"finished file {} >> {} lines ({})\".format(filename,len(lines), len(sublines)))\n",
    "    i=0\n",
    "    for line in lines:\n",
    "        subline=line.lower().split()\n",
    "        for s in subline:\n",
    "            if (s not in stop_words) and (s not in punctuations) and (not s.startswith('#')) and (not s.startswith(\".\")) :\n",
    "                word_dict[s] += 1\n",
    "        i+=1\n",
    "\n",
    "    #sorted(word_dict.items(), key=lambda word_dict : word_dict[1])\n",
    "    #print(word_dict)\n",
    "\n",
    "    maxkey = sorted(word_dict, key=word_dict.get, reverse=True)[:n]\n",
    "\n",
    "    maxvalues = [word_dict[s] for s in maxkey]\n",
    "    result_dict={}\n",
    "    for i in range(len(maxkey)):\n",
    "        #print(\"{:20}   {:10}    {:.2f}%\".format(maxkey[i], maxvalues[i], 100*maxvalues[i]/len(lines)))\n",
    "        result_dict[maxkey[i]] =maxvalues[i]/len(lines)\n",
    "    #maxperctg = 100*np.array(maxvalues)/len(lines)\n",
    "    return result_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished file Twitter-Get-Old-Tweets-Scraper/wedding/tweets_gathered_wedding_#harryandmeghan.csv >> 1316 lines (1316)\n",
      "30\n",
      "<class 'dict'>\n",
      "meghan 0.1458966565349544\n",
      "wedding 0.1398176291793313\n",
      "harry 0.135258358662614\n",
      "prince 0.12613981762917933\n",
      "royal 0.12082066869300911\n",
      "… 0.11322188449848024\n",
      "love 0.07446808510638298\n",
      "duchess 0.06838905775075987\n",
      "windsor 0.057750759878419454\n",
      "duke 0.05623100303951368\n",
      "markle 0.05319148936170213\n",
      "day 0.0425531914893617\n",
      "congratulations 0.04179331306990881\n",
      "like 0.041033434650455926\n",
      "princess 0.041033434650455926\n",
      "first 0.04027355623100304\n",
      "see 0.04027355623100304\n",
      "sussex 0.03951367781155015\n",
      "look 0.03875379939209726\n",
      "beautiful 0.03571428571428571\n",
      "one 0.034954407294832825\n",
      "big 0.03343465045592705\n",
      "today 0.030395136778115502\n",
      "happy 0.02811550151975684\n",
      "get 0.02811550151975684\n",
      "best 0.02735562310030395\n",
      "castle 0.026595744680851064\n",
      "queen 0.026595744680851064\n",
      "watch 0.026595744680851064\n",
      "us 0.025835866261398176\n"
     ]
    }
   ],
   "source": [
    "directory = \"Twitter-Get-Old-Tweets-Scraper/wedding/tweets_gathered_wedding_#harryandmeghan.csv\"\n",
    "n =30\n",
    "word_dict = get_freq_words_hastag(n, directory)\n",
    "\n",
    "#print(word_dict)\n",
    "print(len(word_dict.keys()))\n",
    "print(type(word_dict))\n",
    "for key in word_dict.keys():\n",
    "    print(key , word_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
